import os
import time
import numpy as np
import cupy as cp
import cupyx.scipy.sparse as cpsp
import scanpy as sc

from dask_cuda import LocalCUDACluster
from dask.distributed import Client, wait
import rmm
from rmm.allocators.cupy import rmm_cupy_allocator

# -------------------------------
# Utility class for colored printing
# -------------------------------
class color:
    PURPLE = '\033[95m'
    CYAN = '\033[96m'
    DARKCYAN = '\033[36m'
    BLUE = '\033[94m'
    GREEN = '\033[92m'
    YELLOW = '\033[93m'
    RED = '\033[91m'
    BOLD = '\033[1m'
    UNDERLINE = '\033[4m'
    END = '\033[0m'

# -------------------------------
# Container classes for results
# -------------------------------
class SVDResult:
    def __init__(self, U, s, Vt, explained_variance_ratio):
        self.U = U
        self.s = s
        self.Vt = Vt
        self.explained_variance_ratio_ = [explained_variance_ratio]  # stored as list
        if Vt.shape[0] > 1:
            self.components_ = (Vt[0], Vt[1])
        else:
            self.components_ = (Vt[0], None)

class GeneSetResult:
    def __init__(self, subset, subsetlist, outliers, nullgenesetsize, svd, X, raw_X_subset, nulll1, null_median_exp, null_projections):
        self.subset = subset
        self.subsetlist = subsetlist
        self.outliers = outliers
        self.nullgenesetsize = nullgenesetsize
        self.svd = svd
        self.X = X
        self.raw_X_subset = raw_X_subset
        self.nulll1 = nulll1
        self.null_median_exp = null_median_exp
        self.null_projections = null_projections
        self.p_value = None
        self.q_value = None
        self.non_adj_p = None
        self.non_adj_q = None
        self.test_l1 = None
        self.test_median_exp = None
        self.custom_name = None

# -------------------------------
# ROMA class definition
# -------------------------------
class ROMA:
    def __init__(self, computation_mode="sc"):
        """
        Parameters:
          computation_mode: "sc" for GPU-based single-cell computations.
        """
        self.computation_mode = computation_mode
        self.adata = None         # AnnData object
        self.gmt = None           # Path to GMT file
        self.genesets = {}        # Dictionary of gene sets
        self.idx = None
        self.approx_int = 20
        self.min_n_genes = 10
        self.nullgenesetsize = None
        self.subset = None
        self.subsetlist = None
        self.outliers = []
        self.svd = None
        self.X = None
        self.raw_X_subset = None
        self.nulll1 = []
        self.results = {}
        self.null_distributions = {}
        self.custom_name = color.BOLD + color.GREEN + "scROMA" + color.END
        self.q_L1_threshold = 0.05
        self.q_Med_Exp_threshold = 0.05
        self.gene_weights = {}
        self.pc_sign_mode = 'PreferActivation'
        self.pc_sign_thr = 0.90
        self.def_wei = 1
        self.cor_method = 'pearson'

    def read_gmt_to_dict(self, gmt_path):
        """Read a GMT file and build a dictionary mapping gene set names to gene arrays."""
        genesets = {}
        with open(gmt_path, 'r') as file:
            lines = [line.rstrip('\n') for line in file]
        for line in lines:
            parts = line.split('\t')
            name = parts[0]
            genesets[name] = np.array([gene for gene in parts[2:] if gene != ''])
        self.genesets = genesets
        return genesets

    def indexing(self, adata):
        """Set self.idx to the unique gene names from adata.var.index."""
        self.idx = list(set(adata.var.index.tolist()))

    def subsetting(self, adata, geneset):
        """
        Given a gene set (array of gene names), compute subset and subsetlist.
        """
        subsetlist = geneset[np.isin(geneset, self.idx)]
        subset = adata[:, subsetlist]
        self.subset = subset
        self.subsetlist = subsetlist
        return subset, subsetlist

    def compute_svd_explained_variance(self, X_subset):
        """
        Compute SVD on X_subset (assumed Cupy array or sparse matrix) and return the explained variance ratio.
        """
        X_dense = X_subset.toarray() if cpsp.issparse(X_subset) else X_subset
        import cupy.linalg as cpla
        U, s, Vt = cpla.svd(X_dense, full_matrices=False)
        expl_ratio = (s[0] ** 2) / cp.sum(s ** 2)
        return expl_ratio, U, s, Vt

    def compute_null_distribution(self, n_genes, null_iters=100, batch_size=10):
        """
        Generate a null distribution by randomly sampling n_genes from self.adata.X.
        To reduce memory usage, iterations are processed in batches.
        
        Returns:
          expl_ratios_all: Cupy array of explained variance ratios.
          null_medians_all: Cupy array of median PC1 projections.
          null_projections_all: Cupy array of all PC1 projection vectors.
        """
        import cupy.linalg as cpla
        n_samples, total_genes = self.adata.X.shape
        expl_ratios_list = []
        null_medians_list = []
        null_projections_list = []
        num_batches = (null_iters + batch_size - 1) // batch_size
        for batch in range(num_batches):
            current_batch_size = batch_size if (batch < num_batches - 1) else (null_iters - batch * batch_size)
            submatrices = []
            for i in range(current_batch_size):
                idx = cp.random.choice(total_genes, size=n_genes, replace=False)
                X_subset = self.adata.X[:, idx]
                if cpsp.issparse(X_subset):
                    X_subset = X_subset.toarray()
                submatrices.append(X_subset)
            X_batch = cp.stack(submatrices, axis=0)  # shape: (current_batch_size, n_samples, n_genes)
            U, s, Vt = cpla.svd(X_batch, full_matrices=False)
            expl_ratios = (s[:, 0] ** 2) / cp.sum(s ** 2, axis=1)
            pc1 = Vt[:, 0, :]  # shape: (current_batch_size, n_genes)
            null_projections = cp.sum(X_batch * pc1[:, cp.newaxis, :], axis=2)  # shape: (current_batch_size, n_samples)
            null_medians = cp.median(null_projections, axis=1)
            expl_ratios_list.append(expl_ratios)
            null_medians_list.append(null_medians)
            null_projections_list.append(null_projections)
        expl_ratios_all = cp.concatenate(expl_ratios_list, axis=0)
        null_medians_all = cp.concatenate(null_medians_list, axis=0)
        null_projections_all = cp.concatenate(null_projections_list, axis=0)
        return expl_ratios_all, null_medians_all, null_projections_all

    def select_and_sort_gene_sets(self, selected_gene_sets):
        """Return a list of gene set names (sorted by size) that are present in self.genesets."""
        selected = {name: genes for name, genes in self.genesets.items() if name in selected_gene_sets}
        sorted_sets = sorted(selected.items(), key=lambda x: len(x[1]))
        return [name for name, genes in sorted_sets]

    def assess_significance(self, results):
        """
        Dummy significance assessment.
        Needs to be replaced.
        """
        from statsmodels.stats.multitest import multipletests
        ps = np.zeros(len(results))
        qs = np.zeros(len(results))
        for i, (name, res) in enumerate(results.items()):
            test_l1 = res.svd.explained_variance_ratio_[0]
            p_value = np.mean(np.array(res.nulll1) >= test_l1)
            ps[i] = p_value
            qs[i] = p_value
            res.test_l1 = test_l1
            res.test_median_exp = np.median(res.X.toarray()) if cpsp.issparse(res.X) else np.median(res.X)
        adjusted_ps = multipletests(ps, method='fdr_bh')[1]
        adjusted_qs = multipletests(qs, method='fdr_bh')[1]
        for i, (name, res) in enumerate(results.items()):
            res.p_value = adjusted_ps[i]
            res.non_adj_p = ps[i]
            res.q_value = adjusted_qs[i]
            res.non_adj_q = qs[i]
        return results

    def p_values_in_frame(self, assessed_results):
        """Return a pandas DataFrame of significance results."""
        import pandas as pd
        p_dict, l1_dict, q_dict = {}, {}, {}
        median_exp_dict, non_adj_L1_p_values, non_adj_Med_Exp_p_values = {}, {}, {}
        for k, v in assessed_results.items():
            l1_dict[k] = v.test_l1
            p_dict[k] = v.p_value
            median_exp_dict[k] = v.test_median_exp
            q_dict[k] = v.q_value
            non_adj_L1_p_values[k] = v.non_adj_p
            non_adj_Med_Exp_p_values[k] = v.non_adj_q
        df = pd.DataFrame({
            'L1': pd.Series(l1_dict),
            'ppv L1': pd.Series(non_adj_L1_p_values),
            'Median Exp': pd.Series(median_exp_dict),
            'ppv Med Exp': pd.Series(non_adj_Med_Exp_p_values),
            'q L1': pd.Series(p_dict),
            'q Med Exp': pd.Series(q_dict)
        })
        return df

    def center_sparse(self, X):
        """Center a sparse matrix X by subtracting row and column means."""
        import scipy.sparse as sp
        n_samples, n_features = X.shape
        row_means = np.array(X.mean(axis=1)).flatten().reshape(-1, 1)
        row_mean_matrix = sp.csr_matrix(row_means).dot(sp.csr_matrix(np.ones((1, n_features))))
        X_centered = X - row_mean_matrix
        X_centered = X_centered.tocsc()
        col_means = np.array(X_centered.mean(axis=0)).flatten().reshape(1, -1)
        col_mean_matrix = sp.csc_matrix(np.ones((n_samples, 1))).dot(sp.csc_matrix(col_means))
        X_centered = X_centered - col_mean_matrix
        return X_centered.tocsr()

# -------------------------------
# Dask function: Process one gene set on a specified GPU.
# -------------------------------
def process_gene_set_dask(roma, gene_set_name, null_iters, device_id):
    # This function will run on a Dask worker.
    with cp.cuda.Device(device_id):
        roma.subsetting(roma.adata, roma.genesets[gene_set_name])
        gene_indices = roma.subsetlist
        n_genes = gene_indices.shape[0]
        if n_genes < roma.min_n_genes:
            print(f"Skipping {gene_set_name}: too few genes.")
            return gene_set_name, None
        X_subset = roma.adata[:, gene_indices].X
        expl_ratio, U, s, Vt = roma.compute_svd_explained_variance(X_subset)
        null_expl_ratios, null_median_exp, null_projections = roma.compute_null_distribution(n_genes, null_iters, batch_size=10)
        svd_result = SVDResult(U, s, Vt, expl_ratio)
        gene_set_result = GeneSetResult(
            subset=None,
            subsetlist=gene_indices,
            outliers=None,
            nullgenesetsize=n_genes,
            svd=svd_result,
            X=X_subset.copy(),
            raw_X_subset=roma.adata.raw[:, gene_indices].X,
            nulll1=cp.asnumpy(null_expl_ratios),
            null_median_exp=null_median_exp,
            null_projections=(null_projections, None)
        )
        gene_set_result.custom_name = f"GeneSetResult {gene_set_name}"
        return gene_set_name, gene_set_result

# -------------------------------
# Main compute function using Dask
# -------------------------------
def compute_rapids_dask(roma, selected_gene_sets, null_iters=100):
    """
    Multi-GPU parallel computation of the ROMA pipeline using Dask.
    
    This function:
      - Initializes RMM and sets the Cupy allocator.
      - Converts and centers the expression matrix.
      - Loads and indexes gene sets.
      - Submits each gene set's processing as a Dask task (each pinned to a specific GPU).
      - Gathers results, assesses significance, and stores them in adata.uns.
    """
    from dask.distributed import Client, wait
    import cupyx.scipy.sparse as cpsp

    # Initialize RMM.
    rmm.reinitialize(managed_memory=True, pool_allocator=True, devices=0)
    cp.cuda.set_allocator(rmm_cupy_allocator)

    # Convert adata.X to a Cupy sparse matrix if needed.
    if not cpsp.issparse(roma.adata.X):
        X = cpsp.csr_matrix(cp.asarray(roma.adata.X.T))
    else:
        X = roma.adata.X.T
    roma.adata.X = X.T
    roma.adata.raw = roma.adata.copy()

    # Center the expression matrix.
    row_means = X.mean(axis=1).get()  # Convert to NumPy for tiling
    row_means = cp.asarray(row_means).reshape(-1, 1)
    row_means_expanded = cpsp.csr_matrix(cp.tile(row_means, (1, X.shape[1])))
    X_centered = X - row_means_expanded
    col_means = X_centered.mean(axis=0).get()
    col_means = cp.asarray(col_means).reshape(1, -1)
    col_means_expanded = cpsp.csr_matrix(cp.tile(col_means, (X.shape[0], 1)))
    X_centered = X_centered - col_means_expanded
    roma.adata.X = X_centered.T

    # Build indexing and load gene sets.
    roma.indexing(roma.adata)
    roma.read_gmt_to_dict(roma.gmt)

    if selected_gene_sets == 'all':
        selected_gene_sets = list(roma.genesets.keys())
    else:
        selected_gene_sets = list(set(selected_gene_sets) & set(roma.genesets.keys()))
    sorted_gene_sets = roma.select_and_sort_gene_sets(selected_gene_sets)

    # Determine available GPUs.
    num_devices = cp.cuda.runtime.getDeviceCount()
    print(f"Found {num_devices} GPU(s).")

    # Setup a Dask CUDA cluster using all available GPUs.
    cluster = LocalCUDACluster(CUDA_VISIBLE_DEVICES=",".join(str(i) for i in range(num_devices)))
    client = Client(cluster)
    
    # Scatter the large ROMA object so that it is sent only once.
    roma_future = client.scatter(roma, broadcast=True)
    
    # Submit gene-set tasks. Note: the function process_gene_set_dask receives the scattered object.
    futures = []
    for i, gene_set_name in enumerate(sorted_gene_sets):
        device_id = i % num_devices
        fut = client.submit(process_gene_set_dask, roma_future, gene_set_name, null_iters, device_id)
        futures.append(fut)
    wait(futures)
    
    results = {}
    for fut in futures:
        gene_set_name, gene_set_result = fut.result()
        if gene_set_result is not None:
            results[gene_set_name] = gene_set_result

    # Assess significance.
    assessed_results = roma.assess_significance(results)
    roma.adata.uns['ROMA'] = assessed_results
    roma.adata.uns['ROMA_stats'] = roma.p_values_in_frame(assessed_results)
    if hasattr(roma, "select_active_modules"):
        roma.select_active_modules(roma.q_L1_threshold, roma.q_Med_Exp_threshold)
    roma.custom_name = color.BOLD + color.GREEN + 'scROMA' + color.END + ': module activities are computed'
    print(f"{color.BOLD}{color.PURPLE}Finished{color.END}:")
    
    client.close()
    cluster.close()
    return results

# -------------------------------
# Example usage with Dask
# -------------------------------
# if __name__ == "__main__":
#     # Create a dummy AnnData with 100 samples and 1000 genes.
#     adata = sc.AnnData(np.random.rand(100, 1000))
#     adata.var.index = [f"Gene{i}" for i in range(1000)]
#     
#     # Create a dummy GMT file with two gene sets.
#     gmt_content = (
#         "Pathway_A\tNA\t" + "\t".join([f"Gene{i}" for i in range(100, 200)]) + "\n" +
#         "Pathway_B\tNA\t" + "\t".join([f"Gene{i}" for i in range(300, 400)]) + "\n"
#     )
#     gmt_path = "dummy.gmt"
#     with open(gmt_path, "w") as f:
#         f.write(gmt_content)
#     
#     # Instantiate ROMA.
#     roma = ROMA(computation_mode="sc")
#     roma.adata = adata
#     roma.gmt = gmt_path
#     
#     # Run multi-GPU computation using Dask with 50 null iterations.
#     results = compute_rapids_dask(roma, selected_gene_sets='all', null_iters=50)
#     
#     # Print the summary statistics.
#     print(roma.adata.uns['ROMA_stats'])
